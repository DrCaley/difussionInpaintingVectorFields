# Spatiotemporal UNet, T=13, Gaussian noise — CUDA config (RTX 5070 Ti, 16GB)
# Overrides only — merged with experiments/templates/base_inpaint.yaml

model_name: st_t13_gaussian

# ── Architecture ──────────────────────────────────────────────────
unet_type: spatiotemporal
T: 13
pretrained_spatial_checkpoint: experiments/02_inpaint_algorithm/repaint_gaussian_attn/results/inpaint_gaussian_t250_best_checkpoint.pt

# ── Training ──────────────────────────────────────────────────────
# Freeze-forever mode: spatial weights never unfreeze — only temporal layers train.
# Previous run (v1) showed best test loss at epoch 2 w/ severe overfitting;
# temporal layers have too much capacity (2.06M params) for ~1600 training seqs.
# Mitigations: freeze spatial forever, add temporal dropout, lower LR.
freeze_spatial_epochs: 500       # >= epochs → spatial frozen the entire run
spatial_lr_factor: 0.01          # (unused when freeze-forever, kept for reference)
temporal_dropout: 0.1            # dropout on temporal conv + attention layers
epochs: 500
batch_size: 4                    # RTX 5070 Ti (16GB) — conservative; try 6 if memory allows
gradient_accumulation_steps: 2   # effective batch = 4×2 = 8
lr: 0.0003                       # lower LR (was 0.001) — only temporal layers train
lr_schedule: cosine
warmup_epochs: 10                # longer warmup (was 5) — gentler temporal ramp-up
weight_decay: 0.01
max_grad_norm: 1.0
use_ema: true
eval_max_batches: 100            # cap evaluation to 100 batches (~400 samples) per loader

# ── Noise (Gaussian, same as best 2D model) ──────────────────────
noise_function: gaussian
prediction_target: eps

# ── Unconditional model (no mask/known conditioning) ──────────────
mask_xt: false
p_uncond: 0.0

# ── Hardware ──────────────────────────────────────────────────────
gpu_to_use: 0
num_workers: 4
