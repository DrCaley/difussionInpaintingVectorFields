{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "294f1887",
   "metadata": {},
   "source": [
    "# Train Equalized Div-Free Noise DDPM on Colab\n",
    "\n",
    "Trains the `fwd_diff_eq_divfree` experiment — spectrally-equalized divergence-free noise\n",
    "that fixes the low-frequency spectral gap in standard div-free noise.\n",
    "\n",
    "**Prerequisites:**\n",
    "1. Push latest code to GitHub (including the equalized noise class)\n",
    "2. Upload `stjohn_hourly_5m_velocity_ramhead_v2.mat` (942 MB) to Google Drive\n",
    "   - Put it in: `My Drive/research_data/rams_head/`\n",
    "3. Upload `boundaries.yaml` to the same Drive folder\n",
    "\n",
    "**Runtime:** Select GPU runtime (Runtime → Change runtime type → T4 GPU)\n",
    "\n",
    "**Estimated time:** ~12-15 hours for 1000 epochs on T4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d0bcc6",
   "metadata": {},
   "source": [
    "## 1. Setup: Mount Drive, Clone Repo, Install Deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee31405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive (for data + saving checkpoints)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f387b2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repo\n",
    "import os\n",
    "REPO_URL = 'https://github.com/DrCaley/difussionInpaintingVectorFields.git'\n",
    "REPO_DIR = '/content/diffusionInpaintingVectorFields'\n",
    "\n",
    "if os.path.exists(REPO_DIR):\n",
    "    print(f'Repo already cloned at {REPO_DIR}, pulling latest...')\n",
    "    !cd {REPO_DIR} && git pull\n",
    "else:\n",
    "    !git clone {REPO_URL} {REPO_DIR}\n",
    "\n",
    "%cd {REPO_DIR}\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc43cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (Colab already has torch, numpy, matplotlib)\n",
    "!pip install -q tqdm pyyaml scipy gpytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7123a1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Symlink data from Google Drive into the expected location\n",
    "DRIVE_DATA = '/content/drive/MyDrive/research_data/rams_head'\n",
    "LOCAL_DATA = f'{REPO_DIR}/data/rams_head'\n",
    "\n",
    "os.makedirs(LOCAL_DATA, exist_ok=True)\n",
    "\n",
    "# Symlink the .mat file (942 MB — don't copy, just link)\n",
    "mat_src = f'{DRIVE_DATA}/stjohn_hourly_5m_velocity_ramhead_v2.mat'\n",
    "mat_dst = f'{LOCAL_DATA}/stjohn_hourly_5m_velocity_ramhead_v2.mat'\n",
    "bounds_src = f'{DRIVE_DATA}/boundaries.yaml'\n",
    "bounds_dst = f'{LOCAL_DATA}/boundaries.yaml'\n",
    "\n",
    "for src, dst in [(mat_src, mat_dst), (bounds_src, bounds_dst)]:\n",
    "    if not os.path.exists(dst):\n",
    "        assert os.path.exists(src), f'Missing: {src}\\nUpload to Google Drive first!'\n",
    "        os.symlink(src, dst)\n",
    "        print(f'Linked {dst} → {src}')\n",
    "    else:\n",
    "        print(f'Already exists: {dst}')\n",
    "\n",
    "!ls -lh {LOCAL_DATA}/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9406707b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify GPU is available\n",
    "import torch\n",
    "print(f'CUDA available: {torch.cuda.is_available()}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'Memory: {torch.cuda.get_device_properties(0).total_mem / 1e9:.1f} GB')\n",
    "else:\n",
    "    print('WARNING: No GPU! Go to Runtime → Change runtime type → T4 GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9586e4",
   "metadata": {},
   "source": [
    "## 2. Validate Experiment Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf085feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dry-run to validate config\n",
    "!PYTHONPATH=. python experiments/run_experiment.py \\\n",
    "    --dry-run experiments/01_noise_strategy/fwd_divfree_equalized/config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ccddfd",
   "metadata": {},
   "source": [
    "## 3. Quick Smoke Test (3 epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9847942a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smoke test — verify everything works on GPU before committing to full run\n",
    "!PYTHONPATH=. python experiments/run_experiment.py \\\n",
    "    --smoke experiments/01_noise_strategy/fwd_divfree_equalized/config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f040e24f",
   "metadata": {},
   "source": [
    "## 4. Full Training (1000 epochs)\n",
    "\n",
    "**Important:** Colab may disconnect after ~4-12 hours depending on your plan.\n",
    "The training saves best checkpoint automatically, so you can resume if interrupted.\n",
    "\n",
    "Tips to avoid disconnection:\n",
    "- Keep the browser tab open and active\n",
    "- Colab Pro gives longer runtime (~24h)\n",
    "- Checkpoints are saved to the experiment results/ folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf22b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full training run\n",
    "!PYTHONPATH=. python experiments/run_experiment.py \\\n",
    "    experiments/01_noise_strategy/fwd_divfree_equalized/config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe3d7a3",
   "metadata": {},
   "source": [
    "## 5. Save Results to Google Drive\n",
    "\n",
    "Copy checkpoints to Drive so they survive Colab shutdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18525a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "SRC = f'{REPO_DIR}/experiments/01_noise_strategy/fwd_divfree_equalized/results'\n",
    "DST = '/content/drive/MyDrive/research_data/training_results/fwd_divfree_equalized'\n",
    "\n",
    "os.makedirs(DST, exist_ok=True)\n",
    "\n",
    "# Copy all checkpoint and log files\n",
    "copied = 0\n",
    "for f in os.listdir(SRC):\n",
    "    if f.endswith(('.pt', '.yaml', '.csv', '.png')):\n",
    "        shutil.copy2(os.path.join(SRC, f), os.path.join(DST, f))\n",
    "        print(f'  Copied: {f}')\n",
    "        copied += 1\n",
    "\n",
    "print(f'\\nCopied {copied} files to {DST}')\n",
    "!ls -lh {DST}/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37aeb262",
   "metadata": {},
   "source": [
    "## 6. Resume Training (if interrupted)\n",
    "\n",
    "If Colab disconnected, re-run cells 1-2 (mount + clone), then run this cell.\n",
    "It resumes from the best checkpoint saved in the results folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813657ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, restore checkpoint from Drive if results folder is empty\n",
    "SRC_DRIVE = '/content/drive/MyDrive/research_data/training_results/fwd_divfree_equalized'\n",
    "DST_LOCAL = f'{REPO_DIR}/experiments/01_noise_strategy/fwd_divfree_equalized/results'\n",
    "os.makedirs(DST_LOCAL, exist_ok=True)\n",
    "\n",
    "if os.path.exists(SRC_DRIVE):\n",
    "    for f in os.listdir(SRC_DRIVE):\n",
    "        if f.endswith('.pt'):\n",
    "            dst_path = os.path.join(DST_LOCAL, f)\n",
    "            if not os.path.exists(dst_path):\n",
    "                shutil.copy2(os.path.join(SRC_DRIVE, f), dst_path)\n",
    "                print(f'  Restored: {f}')\n",
    "\n",
    "# Find best checkpoint\n",
    "ckpt = None\n",
    "for f in os.listdir(DST_LOCAL):\n",
    "    if 'best_checkpoint' in f and f.endswith('.pt'):\n",
    "        ckpt = os.path.join(DST_LOCAL, f)\n",
    "        break\n",
    "\n",
    "if ckpt:\n",
    "    print(f'Resuming from: {ckpt}')\n",
    "    # Create a temporary resume config\n",
    "    resume_yaml = os.path.join(DST_LOCAL, 'resume_config.yaml')\n",
    "    with open(resume_yaml, 'w') as f:\n",
    "        f.write(f\"\"\"# Auto-generated resume config\n",
    "model_name: fwd_diff_eq_divfree_eps_t250\n",
    "noise_function: fwd_diff_eq_divfree\n",
    "unet_type: standard\n",
    "prediction_target: eps\n",
    "mask_xt: false\n",
    "p_uncond: 0.0\n",
    "retrain_mode: true\n",
    "model_to_retrain: {ckpt}\n",
    "reset_best: false\n",
    "\"\"\")\n",
    "    !PYTHONPATH=. python experiments/run_experiment.py {resume_yaml}\n",
    "else:\n",
    "    print('No checkpoint found — starting fresh')\n",
    "    !PYTHONPATH=. python experiments/run_experiment.py \\\n",
    "        experiments/01_noise_strategy/fwd_divfree_equalized/config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14111c90",
   "metadata": {},
   "source": [
    "## 7. Download Best Checkpoint Locally\n",
    "\n",
    "After training completes, download the checkpoint to use on your local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8943f609",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "RESULTS = f'{REPO_DIR}/experiments/01_noise_strategy/fwd_divfree_equalized/results'\n",
    "for f in os.listdir(RESULTS):\n",
    "    if 'best_checkpoint' in f and f.endswith('.pt'):\n",
    "        print(f'Downloading: {f}')\n",
    "        files.download(os.path.join(RESULTS, f))\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
