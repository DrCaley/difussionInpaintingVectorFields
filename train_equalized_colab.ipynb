{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "294f1887",
   "metadata": {},
   "source": [
    "# Train Equalized Div-Free Noise DDPM on Colab\n",
    "\n",
    "Trains the `fwd_diff_eq_divfree` experiment — spectrally-equalized divergence-free noise\n",
    "that fixes the low-frequency spectral gap in standard div-free noise.\n",
    "\n",
    "**Training improvements (Feb 2026):**\n",
    "- **Cosine LR schedule** with linear warmup (breaks through Adam plateau)\n",
    "- **AdamW** with weight decay (better generalization)\n",
    "- **EMA** of model weights (smoother inference, standard in DDPM)\n",
    "- **Velocity-aware augmentation** (H/V flips preserving ∇·v=0)\n",
    "- **Full test-set evaluation** (all 1965 samples, not just 320)\n",
    "\n",
    "**Prerequisites:**\n",
    "1. Push latest code to GitHub (including the equalized noise class)\n",
    "2. Upload `stjohn_hourly_5m_velocity_ramhead_v2.mat` (942 MB) to Google Drive\n",
    "   - Put it in: `My Drive/Ocean Inpainting/`\n",
    "3. Upload `boundaries.yaml` to the same Drive folder\n",
    "\n",
    "**Runtime:** Select GPU runtime (Runtime → Change runtime type → T4 GPU)\n",
    "\n",
    "**Estimated time:** ~15-20 hours for 1000 epochs on T4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d0bcc6",
   "metadata": {},
   "source": [
    "## 1. Setup: Mount Drive, Clone Repo, Install Deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee31405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive (for data + saving checkpoints)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f387b2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repo\n",
    "import os\n",
    "REPO_URL = 'https://github.com/DrCaley/difussionInpaintingVectorFields.git'\n",
    "REPO_DIR = '/content/diffusionInpaintingVectorFields'\n",
    "\n",
    "if os.path.exists(REPO_DIR):\n",
    "    print(f'Repo already cloned at {REPO_DIR}, pulling latest...')\n",
    "    !cd {REPO_DIR} && git pull\n",
    "else:\n",
    "    !git clone {REPO_URL} {REPO_DIR}\n",
    "\n",
    "%cd {REPO_DIR}\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc43cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (Colab already has torch, numpy, matplotlib)\n",
    "!pip install -q tqdm pyyaml scipy gpytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7123a1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Symlink data from Google Drive into the expected location\n",
    "DRIVE_DATA = '/content/drive/MyDrive/Ocean Inpainting'\n",
    "LOCAL_DATA = f'{REPO_DIR}/data/rams_head'\n",
    "\n",
    "os.makedirs(LOCAL_DATA, exist_ok=True)\n",
    "\n",
    "# Symlink the .mat file (942 MB — don't copy, just link)\n",
    "mat_src = f'{DRIVE_DATA}/stjohn_hourly_5m_velocity_ramhead_v2.mat'\n",
    "mat_dst = f'{LOCAL_DATA}/stjohn_hourly_5m_velocity_ramhead_v2.mat'\n",
    "bounds_src = f'{DRIVE_DATA}/boundaries.yaml'\n",
    "bounds_dst = f'{LOCAL_DATA}/boundaries.yaml'\n",
    "\n",
    "for src, dst in [(mat_src, mat_dst), (bounds_src, bounds_dst)]:\n",
    "    if not os.path.exists(dst):\n",
    "        assert os.path.exists(src), f'Missing: {src}\\nUpload to Google Drive first!'\n",
    "        os.symlink(src, dst)\n",
    "        print(f'Linked {dst} → {src}')\n",
    "    else:\n",
    "        print(f'Already exists: {dst}')\n",
    "\n",
    "!ls -lh {LOCAL_DATA}/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796d663d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the data.pickle file (train/val/test split from raw .mat)\n",
    "# This is required by DDInitializer and only needs to run once per Colab session\n",
    "import os\n",
    "PICKLE_PATH = f'{REPO_DIR}/data.pickle'\n",
    "\n",
    "if not os.path.exists(PICKLE_PATH):\n",
    "    print('Generating data.pickle from .mat file...')\n",
    "    %cd {REPO_DIR}\n",
    "    !python data_prep/spliting_data_sets.py\n",
    "    assert os.path.exists(PICKLE_PATH), 'data.pickle was not created!'\n",
    "    print(f'Created: {PICKLE_PATH}')\n",
    "else:\n",
    "    print(f'data.pickle already exists: {PICKLE_PATH}')\n",
    "\n",
    "!ls -lh {PICKLE_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9406707b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify GPU is available\n",
    "import torch\n",
    "print(f'CUDA available: {torch.cuda.is_available()}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB')\n",
    "else:\n",
    "    print('WARNING: No GPU! Go to Runtime → Change runtime type → T4 GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9586e4",
   "metadata": {},
   "source": [
    "## 2. Validate Experiment Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf085feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dry-run to validate config\n",
    "!PYTHONPATH=. python experiments/run_experiment.py \\\n",
    "    --dry-run experiments/01_noise_strategy/fwd_divfree_equalized/config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ccddfd",
   "metadata": {},
   "source": [
    "## 3. Quick Smoke Test (3 epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9847942a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smoke test — verify everything works on GPU before committing to full run\n",
    "!PYTHONPATH=. python experiments/run_experiment.py \\\n",
    "    --smoke experiments/01_noise_strategy/fwd_divfree_equalized/config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f040e24f",
   "metadata": {},
   "source": [
    "## 4. Create Colab-Optimized Config & Train (1000 epochs)\n",
    "\n",
    "The experiment config uses local defaults. This cell writes a Colab-specific\n",
    "override with GPU batch size, LR scaling, and all training improvements.\n",
    "\n",
    "**Important:** Colab may disconnect after ~4-12 hours depending on your plan.\n",
    "The training saves best checkpoint automatically, so you can resume if interrupted.\n",
    "\n",
    "Tips to avoid disconnection:\n",
    "- Keep the browser tab open and active\n",
    "- Colab Pro gives longer runtime (~24h)\n",
    "- Checkpoints are saved to the experiment results/ folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf22b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Adjust batch size for your GPU ──\n",
    "COLAB_BATCH_SIZE = 64   # 64 for T4/V100, 128 for A100\n",
    "BASE_LR = 0.0003\n",
    "BASE_BS = 16\n",
    "COLAB_LR = BASE_LR * (COLAB_BATCH_SIZE / BASE_BS)\n",
    "\n",
    "# Write Colab-optimized config with training improvements\n",
    "COLAB_CFG = f'{REPO_DIR}/experiments/01_noise_strategy/fwd_divfree_equalized/colab_config.yaml'\n",
    "\n",
    "with open(COLAB_CFG, 'w') as f:\n",
    "    f.write(f\"\"\"# Auto-generated Colab config — GPU-optimized with training improvements\n",
    "model_name: fwd_diff_eq_divfree_eps_t250\n",
    "noise_function: fwd_diff_eq_divfree\n",
    "unet_type: standard\n",
    "prediction_target: eps\n",
    "mask_xt: false\n",
    "p_uncond: 0.0\n",
    "batch_size: {COLAB_BATCH_SIZE}\n",
    "lr: {COLAB_LR}\n",
    "max_grad_norm: 1.0\n",
    "\n",
    "# ── Training improvements ──\n",
    "weight_decay: 0.0001       # AdamW regularization\n",
    "lr_schedule: cosine        # cosine annealing with warmup\n",
    "warmup_epochs: 10          # linear warmup from lr*0.001 → lr\n",
    "use_ema: true              # exponential moving average of weights\n",
    "ema_decay: 0.9999          # standard DDPM EMA decay\n",
    "augment: false             # disabled — site-specific ocean data shouldn't be flipped\n",
    "\"\"\")\n",
    "\n",
    "print(f'Wrote Colab config: batch_size={COLAB_BATCH_SIZE}, lr={COLAB_LR}')\n",
    "!cat {COLAB_CFG}\n",
    "\n",
    "# Full training run\n",
    "!PYTHONPATH=. python experiments/run_experiment.py {COLAB_CFG}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe3d7a3",
   "metadata": {},
   "source": [
    "## 5. Save Results to Google Drive\n",
    "\n",
    "Copy checkpoints to Drive so they survive Colab shutdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18525a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "SRC = f'{REPO_DIR}/experiments/01_noise_strategy/fwd_divfree_equalized/results'\n",
    "DST = '/content/drive/MyDrive/Ocean Inpainting/training_results/fwd_divfree_equalized'\n",
    "\n",
    "os.makedirs(DST, exist_ok=True)\n",
    "\n",
    "# Copy all checkpoint and log files\n",
    "copied = 0\n",
    "for f in os.listdir(SRC):\n",
    "    if f.endswith(('.pt', '.yaml', '.csv', '.png')):\n",
    "        shutil.copy2(os.path.join(SRC, f), os.path.join(DST, f))\n",
    "        print(f'  Copied: {f}')\n",
    "        copied += 1\n",
    "\n",
    "print(f'\\nCopied {copied} files to {DST}')\n",
    "!ls -lh {DST}/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37aeb262",
   "metadata": {},
   "source": [
    "## 6. Resume Training (if interrupted)\n",
    "\n",
    "If Colab disconnected, re-run cells 1-2 (mount + clone), then run this cell.\n",
    "It resumes from the best checkpoint saved in the results folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813657ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Match your initial config settings ──\n",
    "COLAB_BATCH_SIZE = 64\n",
    "BASE_LR = 0.0003\n",
    "BASE_BS = 16\n",
    "COLAB_LR = BASE_LR * (COLAB_BATCH_SIZE / BASE_BS)\n",
    "\n",
    "# First, restore checkpoint from Drive if results folder is empty\n",
    "SRC_DRIVE = '/content/drive/MyDrive/Ocean Inpainting/training_results/fwd_divfree_equalized'\n",
    "DST_LOCAL = f'{REPO_DIR}/experiments/01_noise_strategy/fwd_divfree_equalized/results'\n",
    "os.makedirs(DST_LOCAL, exist_ok=True)\n",
    "\n",
    "if os.path.exists(SRC_DRIVE):\n",
    "    for f in os.listdir(SRC_DRIVE):\n",
    "        if f.endswith('.pt'):\n",
    "            dst_path = os.path.join(DST_LOCAL, f)\n",
    "            if not os.path.exists(dst_path):\n",
    "                shutil.copy2(os.path.join(SRC_DRIVE, f), dst_path)\n",
    "                print(f'  Restored: {f}')\n",
    "\n",
    "# Find best checkpoint\n",
    "ckpt = None\n",
    "for f in os.listdir(DST_LOCAL):\n",
    "    if 'best_checkpoint' in f and f.endswith('.pt'):\n",
    "        ckpt = os.path.join(DST_LOCAL, f)\n",
    "        break\n",
    "\n",
    "if ckpt:\n",
    "    print(f'Resuming from: {ckpt}')\n",
    "    # Create a temporary resume config with all improvements\n",
    "    resume_yaml = os.path.join(DST_LOCAL, 'resume_config.yaml')\n",
    "    with open(resume_yaml, 'w') as f:\n",
    "        f.write(f\"\"\"# Auto-generated resume config with training improvements\n",
    "model_name: fwd_diff_eq_divfree_eps_t250\n",
    "noise_function: fwd_diff_eq_divfree\n",
    "unet_type: standard\n",
    "prediction_target: eps\n",
    "mask_xt: false\n",
    "p_uncond: 0.0\n",
    "batch_size: {COLAB_BATCH_SIZE}\n",
    "lr: {COLAB_LR}\n",
    "max_grad_norm: 1.0\n",
    "\n",
    "# Training improvements\n",
    "weight_decay: 0.0001\n",
    "lr_schedule: cosine\n",
    "warmup_epochs: 10\n",
    "use_ema: true\n",
    "ema_decay: 0.9999\n",
    "augment: false\n",
    "\n",
    "# Resume settings\n",
    "retrain_mode: true\n",
    "model_to_retrain: {ckpt}\n",
    "reset_best: false\n",
    "\"\"\")\n",
    "    !PYTHONPATH=. python experiments/run_experiment.py {resume_yaml}\n",
    "else:\n",
    "    print('No checkpoint found — starting fresh')\n",
    "    COLAB_CFG = f'{REPO_DIR}/experiments/01_noise_strategy/fwd_divfree_equalized/colab_config.yaml'\n",
    "    !PYTHONPATH=. python experiments/run_experiment.py {COLAB_CFG}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14111c90",
   "metadata": {},
   "source": [
    "## 7. Download Best Checkpoint Locally\n",
    "\n",
    "After training completes, download the checkpoint to use on your local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8943f609",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "RESULTS = f'{REPO_DIR}/experiments/01_noise_strategy/fwd_divfree_equalized/results'\n",
    "for f in os.listdir(RESULTS):\n",
    "    if 'best_checkpoint' in f and f.endswith('.pt'):\n",
    "        print(f'Downloading: {f}')\n",
    "        files.download(os.path.join(RESULTS, f))\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
